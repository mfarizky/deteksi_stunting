{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_excel(\"/home/rmfarizky/Project/deteksi_stunting/Dataset/dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tgl_lahir</th>\n",
       "      <th>j_kel</th>\n",
       "      <th>usia_ukur(bulan)</th>\n",
       "      <th>berat</th>\n",
       "      <th>tinggi</th>\n",
       "      <th>tgl_ukur</th>\n",
       "      <th>Z_BB/TB</th>\n",
       "      <th>Z_BB/U</th>\n",
       "      <th>Z_TB/U</th>\n",
       "      <th>Z_IMT/U</th>\n",
       "      <th>BB/TB</th>\n",
       "      <th>BB/U</th>\n",
       "      <th>TB/U</th>\n",
       "      <th>IMT/U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-03</td>\n",
       "      <td>Laki-laki</td>\n",
       "      <td>58</td>\n",
       "      <td>13.1</td>\n",
       "      <td>97.5</td>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>Gizi Baik</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Gizi Baik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-06</td>\n",
       "      <td>Perempuan</td>\n",
       "      <td>57</td>\n",
       "      <td>12.2</td>\n",
       "      <td>98.5</td>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>-1.87</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>Gizi Baik</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Gizi Baik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>Perempuan</td>\n",
       "      <td>56</td>\n",
       "      <td>12.6</td>\n",
       "      <td>95.5</td>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>Gizi Baik</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Gizi Baik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>Laki-laki</td>\n",
       "      <td>55</td>\n",
       "      <td>14.2</td>\n",
       "      <td>99.3</td>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-1.42</td>\n",
       "      <td>-1.96</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>Gizi Baik</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Gizi Baik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-08-18</td>\n",
       "      <td>Perempuan</td>\n",
       "      <td>53</td>\n",
       "      <td>13.2</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>Gizi Baik</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Gizi Baik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>2022-04-07</td>\n",
       "      <td>Perempuan</td>\n",
       "      <td>9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>67.5</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>Gizi Baik</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Gizi Baik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>2022-04-14</td>\n",
       "      <td>Laki-laki</td>\n",
       "      <td>9</td>\n",
       "      <td>7.6</td>\n",
       "      <td>67.5</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>-1.21</td>\n",
       "      <td>-2.38</td>\n",
       "      <td>-2.52</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>Gizi Baik</td>\n",
       "      <td>Kurang</td>\n",
       "      <td>Pendek</td>\n",
       "      <td>Gizi Baik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>2022-06-04</td>\n",
       "      <td>Perempuan</td>\n",
       "      <td>7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>-2.22</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>-2.12</td>\n",
       "      <td>Gizi Kurang</td>\n",
       "      <td>Kurang</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Gizi Kurang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>2022-06-06</td>\n",
       "      <td>Perempuan</td>\n",
       "      <td>7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>65.5</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>-2.41</td>\n",
       "      <td>-2.46</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>Gizi Baik</td>\n",
       "      <td>Kurang</td>\n",
       "      <td>Pendek</td>\n",
       "      <td>Gizi Baik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>2022-11-07</td>\n",
       "      <td>Perempuan</td>\n",
       "      <td>2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>-1.57</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>Gizi Baik</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Gizi Baik</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tgl_lahir      j_kel  usia_ukur(bulan)  berat  tinggi   tgl_ukur  \\\n",
       "0   2018-04-03  Laki-laki                58   13.1    97.5 2023-01-24   \n",
       "1   2018-05-06  Perempuan                57   12.2    98.5 2023-01-24   \n",
       "2   2018-06-06  Perempuan                56   12.6    95.5 2023-01-24   \n",
       "3   2018-07-03  Laki-laki                55   14.2    99.3 2023-01-24   \n",
       "4   2018-08-18  Perempuan                53   13.2    97.0 2023-01-24   \n",
       "..         ...        ...               ...    ...     ...        ...   \n",
       "619 2022-04-07  Perempuan                 9    7.0    67.5 2023-01-11   \n",
       "620 2022-04-14  Laki-laki                 9    7.6    67.5 2023-01-11   \n",
       "621 2022-06-04  Perempuan                 7    6.5    65.0 2023-01-11   \n",
       "622 2022-06-06  Perempuan                 7    6.1    65.5 2023-01-11   \n",
       "623 2022-11-07  Perempuan                 2    5.6    60.0 2023-01-11   \n",
       "\n",
       "     Z_BB/TB  Z_BB/U  Z_TB/U  Z_IMT/U        BB/TB    BB/U    TB/U  \\\n",
       "0      -0.53    0.52    1.24    -0.22    Gizi Baik  Normal  Normal   \n",
       "1      -1.87   -1.94   -0.89    -1.95    Gizi Baik  Normal  Normal   \n",
       "2      -0.95   -1.43   -1.15    -1.05    Gizi Baik  Normal  Normal   \n",
       "3      -0.40   -1.42   -1.96    -0.36    Gizi Baik  Normal  Normal   \n",
       "4      -0.97   -1.38   -1.18    -0.96    Gizi Baik  Normal  Normal   \n",
       "..       ...     ...     ...      ...          ...     ...     ...   \n",
       "619    -0.81   -1.59   -1.75    -0.68    Gizi Baik  Normal  Normal   \n",
       "620    -1.21   -2.38   -2.52    -1.06    Gizi Baik  Kurang  Pendek   \n",
       "621    -2.22   -2.69   -1.97    -2.12  Gizi Kurang  Kurang  Normal   \n",
       "622    -1.43   -2.41   -2.46    -1.18    Gizi Baik  Kurang  Pendek   \n",
       "623    -0.45   -1.11   -1.57    -0.19    Gizi Baik  Normal  Normal   \n",
       "\n",
       "           IMT/U  \n",
       "0      Gizi Baik  \n",
       "1      Gizi Baik  \n",
       "2      Gizi Baik  \n",
       "3      Gizi Baik  \n",
       "4      Gizi Baik  \n",
       "..           ...  \n",
       "619    Gizi Baik  \n",
       "620    Gizi Baik  \n",
       "621  Gizi Kurang  \n",
       "622    Gizi Baik  \n",
       "623    Gizi Baik  \n",
       "\n",
       "[624 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-27 23:36:45.490894: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-27 23:36:45.492934: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported numpy type: NPY_DATETIME).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/micromamba/envs/hlc/lib/python3.11/site-packages/tensorflow/python/data/util/structure.py:104\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    103\u001b[0m   \u001b[39mif\u001b[39;00m spec \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     spec \u001b[39m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    105\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m   \u001b[39m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    107\u001b[0m   \u001b[39m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/hlc/lib/python3.11/site-packages/tensorflow/python/data/util/structure.py:507\u001b[0m, in \u001b[0;36mtype_spec_from_value\u001b[0;34m(element, use_fallback)\u001b[0m\n\u001b[1;32m    504\u001b[0m     logging\u001b[39m.\u001b[39mvlog(\n\u001b[1;32m    505\u001b[0m         \u001b[39m3\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFailed to convert \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m to tensor: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mtype\u001b[39m(element)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, e))\n\u001b[0;32m--> 507\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCould not build a `TypeSpec` for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m with type \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    508\u001b[0m     element,\n\u001b[1;32m    509\u001b[0m     \u001b[39mtype\u001b[39m(element)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not build a `TypeSpec` for 0     2018-04-03\n1     2018-05-06\n2     2018-06-06\n3     2018-07-03\n4     2018-08-18\n         ...    \n619   2022-04-07\n620   2022-04-14\n621   2022-06-04\n622   2022-06-06\n623   2022-11-07\nName: tgl_lahir, Length: 624, dtype: datetime64[ns] with type Series",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/rmfarizky/Project/deteksi_stunting/Classification.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/rmfarizky/Project/deteksi_stunting/Classification.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_ds \u001b[39m=\u001b[39m tfdf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mpd_dataframe_to_tf_dataset(train_df, label\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mBB/TB\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/micromamba/envs/hlc/lib/python3.11/site-packages/tensorflow_decision_forests/keras/core_inference.py:1177\u001b[0m, in \u001b[0;36mpd_dataframe_to_tf_dataset\u001b[0;34m(dataframe, label, task, max_num_classes, in_place, fix_feature_names, weight, batch_size)\u001b[0m\n\u001b[1;32m   1174\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1175\u001b[0m     output \u001b[39m=\u001b[39m (\u001b[39mdict\u001b[39m(features_dataframe), dataframe[label]\u001b[39m.\u001b[39mvalues)\n\u001b[0;32m-> 1177\u001b[0m   tf_dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mDataset\u001b[39m.\u001b[39;49mfrom_tensor_slices(output)\n\u001b[1;32m   1179\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1180\u001b[0m   \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/hlc/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:831\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[39m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m from_tensor_slices_op\n\u001b[0;32m--> 831\u001b[0m \u001b[39mreturn\u001b[39;00m from_tensor_slices_op\u001b[39m.\u001b[39;49m_from_tensor_slices(tensors, name)\n",
      "File \u001b[0;32m~/micromamba/envs/hlc/lib/python3.11/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:25\u001b[0m, in \u001b[0;36m_from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_from_tensor_slices\u001b[39m(tensors, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 25\u001b[0m   \u001b[39mreturn\u001b[39;00m _TensorSliceDataset(tensors, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/micromamba/envs/hlc/lib/python3.11/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:33\u001b[0m, in \u001b[0;36m_TensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, element, is_files\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     32\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m   element \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39;49mnormalize_element(element)\n\u001b[1;32m     34\u001b[0m   batched_spec \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mtype_spec_from_value(element)\n\u001b[1;32m     35\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensors \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[0;32m~/micromamba/envs/hlc/lib/python3.11/site-packages/tensorflow/python/data/util/structure.py:109\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    104\u001b[0m     spec \u001b[39m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    105\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m   \u001b[39m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    107\u001b[0m   \u001b[39m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m   normalized_components\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 109\u001b[0m       ops\u001b[39m.\u001b[39;49mconvert_to_tensor(t, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcomponent_\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m%\u001b[39;49m i))\n\u001b[1;32m    110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m   \u001b[39m# To avoid a circular dependency between dataset_ops and structure,\u001b[39;00m\n\u001b[1;32m    112\u001b[0m   \u001b[39m# we check the class name instead of using `isinstance`.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m   \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDatasetSpec\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/micromamba/envs/hlc/lib/python3.11/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/micromamba/envs/hlc/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:1443\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1441\u001b[0m \u001b[39m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m   1442\u001b[0m preferred_dtype \u001b[39m=\u001b[39m preferred_dtype \u001b[39mor\u001b[39;00m dtype_hint\n\u001b[0;32m-> 1443\u001b[0m \u001b[39mreturn\u001b[39;00m tensor_conversion_registry\u001b[39m.\u001b[39;49mconvert(\n\u001b[1;32m   1444\u001b[0m     value, dtype, name, as_ref, preferred_dtype, accepted_result_types\n\u001b[1;32m   1445\u001b[0m )\n",
      "File \u001b[0;32m~/micromamba/envs/hlc/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/hlc/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:324\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    322\u001b[0m                                          as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    323\u001b[0m   _ \u001b[39m=\u001b[39m as_ref\n\u001b[0;32m--> 324\u001b[0m   \u001b[39mreturn\u001b[39;00m constant(v, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/micromamba/envs/hlc/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:263\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    168\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    264\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/micromamba/envs/hlc/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:275\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    274\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 275\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    277\u001b[0m const_tensor \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39m_create_graph_constant(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    279\u001b[0m )\n\u001b[1;32m    280\u001b[0m \u001b[39mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/micromamba/envs/hlc/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:285\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    284\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[1;32m    286\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/micromamba/envs/hlc/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m     97\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported numpy type: NPY_DATETIME)."
     ]
    }
   ],
   "source": [
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=\"BB/TB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
